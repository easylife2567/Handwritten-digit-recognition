```markdown /Users/easylife/Project/DNN/PRESENTATION_SCRIPT.md
# 全栈 AI 项目演示演讲稿：浏览器中的手写数字识别

**时长预估**：5-8 分钟
**目标受众**：技术评审、同学或开发者社区
**核心信息**：无需后端服务器，AI 模型可以直接在浏览器中高效运行。

---

## 1. 开场引入 (1 分钟)

**[动作]**：展示 PPT 首页或直接打开 Web 应用界面（空白画板）。

**[台词]**：
“大家好，今天我要展示的是一个‘纯前端’的 AI 应用——手写数字识别系统。
通常我们认为 AI 需要强大的后端服务器支持，但随着 WebAssembly 技术的发展，我们已经可以将深度学习模型直接部署在浏览器中。
这样做的好处显而易见：**零延迟**（无需网络请求）、**隐私安全**（数据不出本地）以及**零部署成本**。
下面我将演示它是如何工作的。”

---

## 2. 功能演示 (2-3 分钟)

### 场景一：基础识别

**[动作]**：

1. 在左侧画板上清晰地写一个数字 **"3"**。
2. 点击“预测”按钮。

**[台词]**：
“首先，我写一个数字 3。大家看右边的柱状图，模型瞬间给出了预测结果，置信度非常高。注意，这中间没有任何数据发送到服务器，所有的计算都是在我的笔记本电脑的 CPU 上通过 WebAssembly 完成的。”

### 场景二：实时交互与纠错

**[动作]**：

1. 点击“清空”。
2. 写一个像 "1" 又像 "7" 的数字。
3. 点击“预测”，查看 Top-3 概率。

**[台词]**：
“我们再试一个模糊一点的数字。模型不仅给出了第一选择，还给出了 Top-3 的概率分布，这在实际应用中对于不确定性的处理非常有价值。”

### 场景三：AI 的‘脑图’（热力图）

**[动作]**：

1. 勾选“显示热力图”。
2. 在画板上写一个 **"8"**。
3. 点击“预测”。

**[台词]**：
“最有趣的功能是这个——**热力图**。很多人觉得 AI 是黑盒，不知道它为什么判断这是 8。
通过‘遮挡分析’技术，我们把模型关注的区域可视化了出来。
（指着热力图中红色的部分）
大家看，这些红色的区域就是模型认为最关键的特征。如果我们擦掉这一笔，模型可能就会把它认成 0 或 3。这让我们不仅知道结果，还能理解 AI 的‘思考过程’。”

---

## 3. 技术解密 (2-3 分钟)

**[动作]**：切换到代码编辑器 (IDE)。

### 环节一：模型训练 (PyTorch)

**[动作]**：打开 `train.py`，快速滚动展示。
**[台词]**：
“这个项目的核心是一个基于 PyTorch 的多层感知机 (MLP)。虽然结构简单，但在 MNIST 数据集上我们训练到了 98% 的准确率。训练完成后，我们通过 `export_onnx.py` 将其导出为通用的 ONNX 格式。”

### 环节二：Web 推理 (ONNX Runtime)

**[动作]**：打开 `web/src/onnx.ts`。
**[台词]**：
“这是前端最关键的代码。我们使用了微软的 ONNX Runtime Web 库。
大家可以看到这里有一段特殊的配置（指着 `wasmPaths`）。我们在开发中遇到了 Vite 和 WebAssembly 的兼容性挑战，通过显式指定 WASM 文件的加载路径和使用 UMD 模块，成功解决了这个问题。
这行代码 `session.run(feeds)` 就是 AI 推理发生的瞬间。”

---

## 4. 总结 (1 分钟)

**[动作]**：回到 Web 应用界面。

**[台词]**：
“总结一下，这个项目演示了从 PyTorch 训练到 Web 端部署的完整链路。
它证明了现在的 Web 浏览器已经具备了运行轻量级 AI 模型的能力。未来，像图像分割、风格迁移甚至本地 LLM 都可以通过这种方式运行在用户的浏览器里。
我的演示就到这里，谢谢大家！”
```
